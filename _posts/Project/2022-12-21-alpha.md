---
title: "[í”„ë¡œì íŠ¸] Vision based Automous Human Following Wheeled Mobile Robot"
last_modified_at: 2022-12-20
categories:
  - Project
excerpt: "Inha univ, Alpha project"
use_math: true
classes: wide
---

> Inha univ, Alpha project  
[[code](https://github.com/hytric/strereo_depth)]  
Author: Jongha Kim
>   

## Reviews
ì´ë²ˆ í”„ë¡œì íŠ¸ëŠ” Vision ê¸°ë°˜ì˜ ììœ¨ ì£¼í–‰ ë¡œë´‡ì„ ê°œë°œí•˜ëŠ” ê²ƒìœ¼ë¡œ, ì‚¬ëŒì„ ì¸ì‹í•˜ê³  ë”°ë¼ê°€ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ê²ƒì´ ì£¼ìš” ëª©í‘œì˜€ìŠµë‹ˆë‹¤. ì£¼ì–´ì§„ í”Œë«í¼ì€ TurtleBot3 Burgerì™€ Intel Realsense T265 ì¹´ë©”ë¼ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ SLAM(ë™ì‹œì  ì§€ë„ ì‘ì„± ë° ìœ„ì¹˜ ì¶”ì •)ê³¼ ë‚´ë¹„ê²Œì´ì…˜ì„ ì‹¤í˜„í•˜ê³ , ë¡œë´‡ì´ ì¼ì • ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ë©° ì‚¬ëŒì„ ì¶”ì í•  ìˆ˜ ìˆë„ë¡ Depth mapì„ ì‘ì„±í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.  

### Technical challenges and solutions
í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ í° ê¸°ìˆ ì  ë„ì „ì€ Intel Realsense T265 ì¹´ë©”ë¼ì˜€ìŠµë‹ˆë‹¤. ì´ ì¹´ë©”ë¼ëŠ” ë³¸ë˜ Depth mapì„ ìœ„í•œ ì¹´ë©”ë¼ê°€ ì•„ë‹ˆë¼ ìê¸° ìœ„ì¹˜ë¥¼ ì¶”ì í•˜ëŠ” ì¹´ë©”ë¼ë¡œ ì„¤ê³„ëœ ì œí’ˆì´ì—ˆê¸° ë•Œë¬¸ì—, ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹Šì´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ì‰½ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Depth map ì‘ì„±ì„ ìœ„í•´ì„œëŠ” Intel Realsense D435iì™€ ê°™ì€ ê¹Šì´ ì¸¡ì •ì— íŠ¹í™”ëœ ì¹´ë©”ë¼ê°€ ì‚¬ìš©ë˜ì§€ë§Œ, ì£¼ì–´ì§„ í™˜ê²½ì—ì„œ T265ë§Œì„ ì´ìš©í•´ í•´ê²°í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.  

ì´ë¥¼ ìœ„í•´ Stereo Vision ê¸°ë²•ì„ ì ìš©í•˜ì˜€ìœ¼ë©°, OpenCVì˜ StereoSGBM ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ë‘ ê°œì˜ ì–´ì•ˆ ë Œì¦ˆë¡œ ì–»ì€ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨ì´ë§µ(Disparity map)ì„ ê³„ì‚°í•˜ì—¬ ê¹Šì´ë¥¼ ì¶”ì •í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¨ìˆœíˆ í”½ì…€ ê°„ ë°ê¸° ì°¨ì´ë¥¼ ë¹„êµí•˜ëŠ” ë°©ì‹ì€ ì •í™•ë„ê°€ ë‚®ì•˜ìœ¼ë©°, ì™œê³¡ëœ í”„ë ˆì„ìœ¼ë¡œ ì¸í•´ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë°©ë²•ì„ ëª¨ìƒ‰í–ˆìœ¼ë©°, ë…¸ì´ì¦ˆ ì œê±°ì™€ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”ì— ëŒ€í•œ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.  

ì˜ˆë¥¼ ë“¤ì–´, Sum of Absolute Difference(SAD) ë°©ì‹ ëŒ€ì‹  Sum of Squared Difference(SSD)ë‚˜ NCC(Normalized Cross-Correlation) ë“±ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ë„ ê³ ë ¤í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íƒêµ¬ëŠ” Disparity mapì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë° ì¤‘ìš”í•œ ê¸°ì´ˆê°€ ë˜ì—ˆìœ¼ë©°, í”„ë¡œì íŠ¸ê°€ ì§„í–‰ë¨ì— ë”°ë¼ ì´ëŸ¬í•œ ê¸°ìˆ ì  ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” ê³¼ì •ì—ì„œ ë§ì€ ë°°ì›€ì„ ì–»ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.  

í”„ë¡œì íŠ¸ì˜ ìµœì¢… ê²°ê³¼ë¬¼ì€ ì™„ë²½í•˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ì œí•œëœ ìì›ê³¼ ê¸°ìˆ ì  í•œê³„ ì†ì—ì„œë„ ë¡œë´‡ì´ ì‚¬ëŒì„ ë”°ë¼ê°€ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ë ¤ê³  ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, Depth mapì˜ ì •í™•ë„ê°€ ë–¨ì–´ì§ì—ë„ ë¶ˆêµ¬í•˜ê³  ROS(Robot Operating System)ì™€ ë‹¤ì–‘í•œ ì„¼ì„œë“¤ì„ ê²°í•©í•´ ì£¼í–‰ì„ ì‹œë„í–ˆìŠµë‹ˆë‹¤.  

### Post-project experiences
ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ê¸°ìˆ ì ìœ¼ë¡œ ë§ì€ ì„±ì¥ì„ ê²½í—˜í•  ìˆ˜ ìˆì—ˆê³ , ì–´ë ¤ìš´ ìƒí™© ì†ì—ì„œë„ ì£¼ë„ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì´ëŒë©° ë¬¸ì œë¥¼ í•´ê²°í•´ ë‚˜ê°€ëŠ” ê³¼ì •ì—ì„œ íŒ€ì›Œí¬ì™€ ë¦¬ë”ì‹­ ë˜í•œ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ì— ëŒ€í•œ í¬ìŠ¤í„° ì‘ì„±ì„ í†µí•´ ì‘ì—…ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³  ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš¸ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½í—˜ì€ ì—°êµ¬ ê²°ê³¼ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í–ˆìœ¼ë©°, ì´í›„ ì—°êµ¬ ë°œí‘œì—ì„œë„ í° ë„ì›€ì´ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.  

ìµœì¢…ì ìœ¼ë¡œ 2022-2í•™ê¸° ì„±ê³¼ ë°œí‘œíšŒì—ì„œ ìœµí•© í”„ë¡œì íŠ¸ ì¥ë ¤ìƒì„ ìˆ˜ìƒí•˜ë©´ì„œ, ê·¸ê°„ì˜ ë…¸ë ¥ì„ ì¸ì •ë°›ì„ ìˆ˜ ìˆì–´ ë§¤ìš° ë³´ëŒ ìˆì—ˆìŠµë‹ˆë‹¤. ë¹„ë¡ ê²°ê³¼ë¬¼ì´ ì™„ë²½í•˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ì´ë¥¼ í†µí•´ ì–»ì€ ê¸°ìˆ ì  ê²½í—˜ê³¼ ë°°ì›€ì€ ì•ìœ¼ë¡œì˜ í”„ë¡œì íŠ¸ì™€ ì—°êµ¬ì— í° ë„ì›€ì´ ë  ê²ƒì´ë¼ í™•ì‹ í•©ë‹ˆë‹¤.  

---  

## Goal

ì¹´ë©”ë¼ë¥¼ í†µí•´ ì–»ì€ ì‹œê° ì •ë³´ë¡œ ì „ë°©ì— ì‚¬ëŒì„ ë”°ë¼ê°€ëŠ” ë¡œë´‡ ì œì‘

1. ë¡œë´‡ ê¸°ì´ˆ ì„¸íŒ…
2. slam, navigation í™•ì¸
3. ì¼ì • ê±°ë¦¬ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•œ Depth map ì‘ì„±
4. ë™ì‘ í”„ë¡œê·¸ë¨ ì‘ì„±

## Platform specs

- ëª¨ë°”ì¼ ë¡œë´‡ í”Œë«í¼: TurtleBot3 Burger
- MCU: Lattepanda
    - OS: Ubuntu 18.04 LTS
    - Middleware: ROS melodic
- OpenCR 1.0 ì‚¬ìš©
- remote PC: NUC
    - OS: Ubuntu 18.04 LTS
    - Middleware: ROS melodic
- ì„¼ì„œ: Intel Realsense T265

---

## First Setup

### Turtlebot3 emanual

[ROBOTIS e-Manual](https://emanual.robotis.com/docs/en/platform/turtlebot3/overview/)

<img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/Untitled.png" alt="Untitled" width="400">

**Turtlebot setup**

![Untitled](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/Untitled%201.png)

1. PC setup : Master ì—­í• ì„ í•  PC - Ubuntu 18.04
2. SBC setup : as - ROS Melodic
3. OpenCR setup
    - Open-source Control Module for ROS - ì„¼ì„œì™€ ëª¨í„°ë¥¼ ë™ì‘ì‹œí‚¤ëŠ” PCì™€ì˜ ì¤‘ê°„ ë§¤ê°œì²´
    - OpenCR ë³´ë“œë¥¼ ë¼ë–¼íŒë‹¤ ë³´ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëª¨ë“ˆ ì„¤ì¹˜
4. Bring up
    - roscore ëª…ë ¹ì–´ë¥¼ í†µí•´ Masterì™€ Turtlebotì„ ì—°ê²°
    - `roslaunch turtlebot3_bringup turtlebot3_robot.launch`

---

## slam, navigation

Slam

![Untitled](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/Untitled%202.png)

Navigation

<img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/KakaoTalk_20221215_150248160.jpg" alt="KakaoTalk_20221215_150248160.jpg" width="400">

---

## Depth map [[code](https://github.com/hytric/strereo_depth)]

**Camera senser : Intel Realsense T265**

![image.png](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/image.png)

ì–´ì•ˆ ë Œì¦ˆ ì„¼ì„œ 2ê°œ, IMU ë° VPU 2ê°œ

### Problem

- í•´ë‹¹ ì¹´ë©”ë¼ëŠ” depth mapì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì¹´ë©”ë¼ê°€ ì•„ë‹Œ í˜„ì¬ ìì‹ ì˜ ìœ„ì¹˜ë¥¼ trackingí•˜ëŠ”ë° íŠ¹í™”ëœ ì¹´ë©”ë¼
- ì¼ë°˜ì ìœ¼ë¡œ Intel Realsense D435i ì¼ë°˜ ë Œì¦ˆ ì¹´ë©”ë¼ì™€ í•¨ê»˜ ì‚¬ìš©

í•˜ì§€ë§Œ ìš°ë¦¬ì—ê²Œ ì£¼ì–´ì§„ ì¹´ë©”ë¼ëŠ” **Intel Realsense T265** í•˜ë‚˜ ë¿ ì´ì˜€ë‹¤.

ì™œê³¡ëœ í”„ë ˆì„ì—ì„œ depth mapì„ ë½‘ì•„ë‚´ì•¼í•œë‹¤.

### Node list

- intel realsense t265 node list
    
    /camera/accel/imu info  
    /camera/accel/metadata  
    /camera/accel/sample  
    /camera/fisheye1/camera info  
    /camera/fisheye1/image_raw  
    /camera/fisheye1/metadata  
    /camera/fisheye2/camera_info  
    /camera/fisheye2/image_raw  
    /camera/fisheye/metadata  
    /camera/gyro/imu_info  
    /camera/gyro/metadata  
    /camera/gyro/sample  
    /camera/odom/metadata  
    /camera /odom/sample  
    /camera/realsensez_camera_manager / bond  
    /camera/tracking_module/parameter_descriptions  
    /camera/tracking_module/parameter _updates  
    /diagnostics  
    /rosout  
    /rosout_agg  
    /tf /tf_static  
    

### Background

[Pythonê³¼ OpenCV - 46 : ìŠ¤íŠ¸ë ˆì˜¤ ì´ë¯¸ì§€ë¡œë¶€í„° ê¹Šì´ ë§µ(Depth Map) ìƒì„±í•˜ê¸°](http://www.gisdeveloper.co.kr/?p=6955)

![Untitled](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/Untitled%203.png)

```python
stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)
disparity = stereo.compute(imgL,imgR)
```

- OpenCV ëª¨ë“ˆ ë‚´ì— compute í•¨ìˆ˜ë¥¼ ì‚¬ìš©

<aside>
ğŸ’¡

2ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬ [stereo sgbm ê³¼ stereo bm]

| Stereo SGBM | StereoBM  |
| --- | --- |
| ê° í”½ì…€ ë˜ëŠ” ë¸”ë¡ì— ëŒ€í•´ ë¹„ìš© í•¨ìˆ˜(cost function)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ì˜ì—­ì„ ì°¾ê³ , ê·¸ ì°¨ì´(disparity)ë¥¼ ê³„ì‚°í•˜ì—¬ ê¹Šì´ ë§µì„ ìƒì„± | ì—¬ëŸ¬ ë°©í–¥ì—ì„œ ë§¤ì¹­ ë¹„ìš©ì„ í•©ì‚°í•´ ë°˜-ì „ì—­ì ì¸(semi-global) ë°©ì‹ìœ¼ë¡œ ìµœì í™” |
| ë¹„êµì  ë‹¨ìˆœí•œ ë°©ë²•ì´ì§€ë§Œ, ì¡°ëª… ë³€í™”ë‚˜ ì§ˆê°ì´ ì ì€ ì˜ì—­ì—ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ | ì „ì—­ì  ìµœì í™”ë¡œ ì¸í•´ ë³µì¡í•œ ì§€í˜•ì˜ ê¹Šì´ ë§µì„ ë” ì •í™•í•˜ê²Œ ì¶”ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì¡°ëª… ë³€í™”ë‚˜ ì§ˆê°ì´ ì—†ëŠ” ì˜ì—­ì—ì„œë„ ìƒëŒ€ì ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥

ë” ë³µì¡í•˜ê³  ë†’ì€ ê³„ì‚° ë¹„ìš© |
</aside>

### CV2ì˜ ì´ë¯¸ì§€ í‘œí˜„ ë°©ì‹

Numpy(ë¦¬ìŠ¤íŠ¸ì™€ ìœ ì‚¬)ë¡œ ì •ë¦¬ëœ ê° ìˆ«ìì˜ í¬ê¸°ë²”ìœ„ ë‚´ì—ì„œ ìˆ«ìê°€ í¬ë©´ í•˜ì–€ìƒ‰ ì‘ì„ìˆ˜ë¡ ê²€ì€ìƒ‰ì„ ì¹ í•¨ ê° í”½ì…€ ìˆ˜ë§Œí¼ ì´ë¯¸ì§€ê°€ ë‚˜ì˜´ ë²”ìœ„ëŠ” 0~1ì´ê³  0.ì•„ë˜ëŠ” ê²€ì • 1ì´ìƒì€ í•˜ì–€ìƒ‰

```python
import cv2
import numpy as np
dis = np.arange(1000000).reshape(1000,1000)
print(dis)
img = np.array(dis, dtype=np.uint8) # ì—¬ê¸°ì„œ ë³€í™˜
cv2.imshow('disparity',dis/1000000)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

ë‹¤ìŒ ì½”ë“œì„ ë³´ë©´

1000 * 1000 í–‰ë ¬

[[     0      1      2 ...    997    998    999]
[  1000   1001   1002 ...   1997   1998   1999]
[  2000   2001   2002 ...   2997   2998   2999]
...
[997000 997001 997002 ... 997997 997998 997999]
[998000 998001 998002 ... 998997 998998 998999]
[999000 999001 999002 ... 999997 999998 999999]]

![image.png](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/image%201.png)

100 * 100 í–‰ë ¬
[[   0    1    2 ...   97   98   99]
[ 100  101  102 ...  197  198  199]
[ 200  201  202 ...  297  298  299]
...
[9700 9701 9702 ... 9797 9798 9799]
[9800 9801 9802 ... 9897 9898 9899]
[9900 9901 9902 ... 9997 9998 9999]]

![image.png](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/image%202.png)

ê¹Šì´ ê³„ì‚°
`disparity = stereo.compute(rect_left_image, rect_right_image).astype(np.float32)/16`
ê³„ì‚°í•œ ê°’ì„ 0~1ì‚¬ì´ë¡œ ì¡°ì •
`disparity = (disparity - minDisp) / numDisp`

### ì™œ disparity Map(ì°¨ì´ ë§µ)ì˜ ì„±ëŠ¥ì€ ì¢‹ì§€ ì•Šì€ê°€?

[[ì˜ìƒì‹ í˜¸ì²˜ë¦¬] Disparity Map ê°œë… ì´í•´](https://velog.io/@se0yeon00/%EC%98%81%EC%83%81%EC%8B%A0%ED%98%B8%EC%B2%98%EB%A6%AC-Disparity-Map-%EA%B0%9C%EB%85%90-%EC%9D%B4%ED%95%B4)

**Disparity Map**ì€ ìŠ¤í…Œë ˆì˜¤ ë¹„ì „ ì‹œìŠ¤í…œì—ì„œ ë‘ ê°œì˜ ì¹´ë©”ë¼(ë˜ëŠ” ë‘ ê°œì˜ ì‹œì )ë¡œ ì´¬ì˜í•œ ì´ë¯¸ì§€ ê°„ì˜ **ì‹œì°¨(Disparity)**ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒì„±ëœ 2D ì´ë¯¸ì§€

ìœ„ì˜ ì‚¬ì§„ë“¤ì—ì„œ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯ì´, disparity Mapì˜ ê²°ê³¼ê°€ ê·¸ë ‡ê²Œ ì¢‹ì€ í¸ì€ ì•„ë‹ˆë‹¤. ì´ ì´ìœ ì— ëŒ€í•œ íƒêµ¬ë¥¼ ì§„í–‰í•´ë³´ì•˜ëŠ”ë°, ì§€ê¸ˆ ì‘ì„±í•œ ì½”ë“œê°€ ë‹¨ìˆœíˆ í”½ì…€ê°„ì˜ ë°ê¸° ê°’ ì°¨ì´ë§Œ ë¹„êµí•˜ëŠ” í”„ë¡œê·¸ë¨ì´ê¸° ë•Œë¬¸ì— ê·¸ëŸ´ ê²ƒì´ë¼ëŠ” ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ìˆì—ˆë‹¤. ë‹¨ìˆœíˆ ê±°ë¦¬ê°’ë§Œ ë¹„êµí•˜ëŠ” ê³¼ì •ì—” ë§ì€ ì˜ˆì™¸ ì‚¬í•­ì´ ì¡´ì¬í•œë‹¤.

ê³ ë¡œ, ë” ë‚˜ì€ disparity Mapì„ ì–»ê¸° ìœ„í•´ì„  í”½ì…€ ë°ê¸° ê°’ ì°¨ì´ë¥¼ ë” ì˜ ë¹„êµí•´ì¤„ ì•Œê³ ë¦¬ì¦˜ì„ ì¶”ê°€ì ìœ¼ë¡œ ì´ìš©í•œë‹¤ê±°ë‚˜, ë…¸ì´ì¦ˆë¥¼ canceling í•´ì¤„ íš¨ê³¼ì ì¸ ë°©ë²•ì„ ì¶”ê°€ì ìœ¼ë¡œ ë„ì…í•  í•„ìš”ì„±ì´ ìˆë‹¤. í¥ë¯¸ê°€ ìƒê²¨ ì¸í„°ë„·ì„ íƒìƒ‰í•´ë³´ë‹ˆ, disparity Mapì˜ ì„±ëŠ¥ì„ ì¢‹ê²Œ í•´ì¤„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ belief propagation ë“± ì„ ì‚¬ìš©í•˜ê±°ë‚˜, í”½ì…€ê°„ì˜ ê±°ë¦¬ íƒìƒ‰ì—ì„œ SAD(Sum of Absolute difference, ë³¸ ì½”ë“œì—ì„œ ì‚¬ìš©í•œ ë°©ë²•) ëŒ€ì‹  SSD(Sum of Squared difference)ë‚˜ NCC ë“±ì„ ì‚¬ìš©í•´ ë°ê¸° ì°¨ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ìˆìŒì„ ìƒˆë¡­ê²Œ ì•Œê²Œ ë˜ì—ˆë‹¤.

### stereo camera depth data

ìœ„ì˜ ì˜ˆì‹œë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì´ìš©í–ˆë‹¤.

[Ubuntuã§Intel RealSense T265ã‚’å‹•ã‹ã—ã¦ã¿ãŸ](https://asukiaaa.blogspot.com/2019/04/ubuntuintel-realsense-t265.html)

ìê¸° ìœ„ì¹˜ ë°˜í™˜

![Untitled](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/Untitled%204.png)

**ë³€í˜•í•œ ì½”ë“œ**

```python
#!/usr/bin/python
# -*- coding: utf-8 -*-

# First import the library
import pyrealsense2 as rs
import numpy as np
import cv2

# setup opencv stereo
minDisp = 0
numDisp = 64 - minDisp
windowSize = 5
stereo = cv2.StereoSGBM_create(
    minDisparity = minDisp,
    numDisparities = numDisp,
    blockSize = 16,
    P1 = 8*3*windowSize**2,
    P2 = 32*3*windowSize**2,
    disp12MaxDiff = 1,
    uniquenessRatio = 10,
    speckleWindowSize = 100,
    speckleRange = 32
)

# Declare RealSense pipeline, encapsulating the actual device and sensors
pipe = rs.pipeline()

# Build config object and request pose data
cfg = rs.config()
cfg.enable_stream(rs.stream.fisheye, 1)
cfg.enable_stream(rs.stream.fisheye, 2)

# Start streaming with requested config
pipe.start(cfg)
print('press q to quit this program')

try:
    while True:
        # Wait for the next set of frames from the camera
        frames = pipe.wait_for_frames()

        # Get images
        # fisheye 1: left, 2: right
        fisheye_left_frame = frames.get_fisheye_frame(1)
        fisheye_right_frame = frames.get_fisheye_frame(2)
        fisheye_left_image = np.asanyarray(fisheye_left_frame.get_data())
        fisheye_right_image = np.asanyarray(fisheye_right_frame.get_data())

        # Calculate disparity
        width = fisheye_left_frame.get_width()
        height = fisheye_left_frame.get_height()
        x1 = int(width/3 - numDisp / 2)
        x2 = int(width*2/3 + numDisp / 2)
        y1 = int(height/3)
        y2 = int(height*2/3)
        rect_left_image = fisheye_left_image[y1:y2, x1:x2]
        rect_right_image = fisheye_right_image[y1:y2, x1:x2]
        disparity = stereo.compute(rect_left_image, rect_right_image).astype(np.float32)/16
        disparity = (disparity - minDisp) / numDisp

        rows, columns = disparity.shape
        temp = np.ones(shape=(1, rows), dtype=np.float32)
        line = (temp @ disparity).argmax()

        # Display images
        cv2.rectangle(fisheye_left_image, (x1, y1), (x2, y2), (255,255,255), 5)
        cv2.rectangle(fisheye_right_image, (x1, y1), (x2, y2), (255,255,255), 5)
        cv2.line(disparity,(line, 0), (line, rows), (255, 255, 0), thickness=10, lineType=cv2.LINE_AA)
        cv2.imshow('fisheye target', np.hstack((fisheye_left_image, fisheye_right_image)))
        cv2.imshow('disparity', disparity)

        key = cv2.waitKey(1)
        if key == ord('q'):
            break

finally:
    pipe.stop()
```  


## Result image

<center>
    <div style="display: flex; flex-wrap: wrap; justify-content: center;">
        <img src="{{ '/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/Untitled%205.png' | relative_url }}" style="width: 40%; margin: 10px;">
        <img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/20.png" alt="20.png" style="width: 40%; margin: 10px;">
        <img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/right.png" alt="right.png" style="width: 40%; margin: 10px;">
        <img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/10.png" alt="10.png" style="width: 40%; margin: 10px;">
        <img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/30.png" alt="30.png" style="width: 40%; margin: 10px;">
        <img src="/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/left.png" alt="left.png" style="width: 40%; margin: 10px;">
    </div>
</center>



---

## ì„±ê³¼ë°œí‘œíšŒ ë° ê²°ê³¼

ì¸í•˜ëŒ€í•™êµ ì•ŒíŒŒí”„ë¡œì íŠ¸ TEAM. TurtleShip í”„ë¡œì íŠ¸

**2022-2í•™ê¸° ìœµí•©í”„ë¡œì íŠ¸ ì¥ë ¤ìƒ ìˆ˜ìƒ**

![KakaoTalk_20221219_145951092.jpg](/assets/Images/2022-12-21-Vision based Automous Human Following Wheeled Mobile Robot/KakaoTalk_20221219_145951092.jpg)